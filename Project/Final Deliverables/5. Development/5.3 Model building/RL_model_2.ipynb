{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL BUILDING**\n",
        "\n",
        "## **4.Reinforcement Learning Model for Cyclone and Flood**"
      ],
      "metadata": {
        "id": "uuDJU_qrusQh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#*Import Dependencies*"
      ],
      "metadata": {
        "id": "twi9wuFom8y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym \n",
        "from gym import Env\n",
        "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete \n",
        "import numpy as np\n",
        "import random\n",
        "import os\n"
      ],
      "metadata": {
        "id": "zafS4ha7mcOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install stable_baselines3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD-avJ4M4vsV",
        "outputId": "b100c2a7-8fa1-41f4-bfc0-0287c002aca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: stable_baselines3 in /usr/local/lib/python3.7/dist-packages (1.6.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (1.5.0)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (1.12.1+cu113)\n",
            "Requirement already satisfied: importlib-metadata~=4.13 in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (4.13.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (1.3.5)\n",
            "Requirement already satisfied: gym==0.21 in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (0.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata~=4.13->stable_baselines3) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata~=4.13->stable_baselines3) (3.10.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->stable_baselines3) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable_baselines3) (2022.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import VecFrameStack\n",
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ],
      "metadata": {
        "id": "XbWSfeYt4fRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Building an environment*"
      ],
      "metadata": {
        "id": "iaO2I7UlngLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Water_DisasterEnv(Env):\n",
        "    def __init__(self):\n",
        "        # Actions we can take: closed room, stay, vacate\n",
        "        self.action_space = Discrete(3)\n",
        "        # Temperature array\n",
        "        self.observation_space = Box(low=np.array([0]), high=np.array([100]))\n",
        "        # Set start rainfall\n",
        "        self.state = 10 + random.randint(-3,3)\n",
        "        # Set decision duration\n",
        "        self.decision_duration = 60\n",
        "        \n",
        "    def step(self, action):\n",
        "        # Apply action\n",
        "        # 0 -1 = -1 rainfall\n",
        "        # 1 -1 = 0 \n",
        "        # 2 -1 = 1 rainfall \n",
        "        self.state += action -1 \n",
        "        # Reduce decision duration by 1 minute\n",
        "        self.decision_duration -= 1 \n",
        "        \n",
        "        # Calculate reward\n",
        "        if self.state >=10 and self.state <=20: \n",
        "            reward =1 \n",
        "        else: \n",
        "            reward = -1 \n",
        "        \n",
        "        # Check if time is over\n",
        "        if self.decision_duration <= 0: \n",
        "            done = True\n",
        "        else:\n",
        "            done = False\n",
        "        \n",
        "        # Apply rainfall fluctuations\n",
        "        #self.state += random.randint(-1,1)\n",
        "        # Set placeholder for info\n",
        "        info = {}\n",
        "        \n",
        "        # Return step information\n",
        "        return self.state, reward, done, info\n",
        "\n",
        "    def render(self):\n",
        "        # Implement viz\n",
        "        pass\n",
        "    \n",
        "    def reset(self):\n",
        "        # Reset rainfall\n",
        "        self.state = np.array([15 + random.randint(-3,3)]).astype(float)\n",
        "        # Reset decision duration\n",
        "        self.decision_duration = 60 \n",
        "        return self.state"
      ],
      "metadata": {
        "id": "G1pbMfsrm8RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = Water_DisasterEnv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyBBuKTxzELi",
        "outputId": "326349cc-31af-4108-b9e9-21d51e81c694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/spaces/box.py:128: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  -self.np_random.exponential(size=upp_bounded[upp_bounded].shape)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.observation_space.sample()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKmE4N6i05Mt",
        "outputId": "29232251-7133-4650-a91f-859c3bc942b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([68.27607], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Test Environment*"
      ],
      "metadata": {
        "id": "RCA_svPh1Y8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = 100\n",
        "for episode in range(1, episodes+1):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    score = 0 \n",
        "    \n",
        "    while not done:\n",
        "        env.render()\n",
        "        action = env.action_space.sample()\n",
        "        n_state, reward, done, info = env.step(action)\n",
        "        score+=reward\n",
        "    print('Episode:{} Score:{}'.format(episode, score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrBhXXwz1yob",
        "outputId": "4cfb4f27-cb44-4caf-c572-ada51bfe9385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode:1 Score:-14\n",
            "Episode:2 Score:60\n",
            "Episode:3 Score:16\n",
            "Episode:4 Score:32\n",
            "Episode:5 Score:-4\n",
            "Episode:6 Score:2\n",
            "Episode:7 Score:-26\n",
            "Episode:8 Score:30\n",
            "Episode:9 Score:50\n",
            "Episode:10 Score:24\n",
            "Episode:11 Score:26\n",
            "Episode:12 Score:52\n",
            "Episode:13 Score:34\n",
            "Episode:14 Score:60\n",
            "Episode:15 Score:28\n",
            "Episode:16 Score:60\n",
            "Episode:17 Score:30\n",
            "Episode:18 Score:22\n",
            "Episode:19 Score:6\n",
            "Episode:20 Score:58\n",
            "Episode:21 Score:38\n",
            "Episode:22 Score:42\n",
            "Episode:23 Score:28\n",
            "Episode:24 Score:20\n",
            "Episode:25 Score:60\n",
            "Episode:26 Score:32\n",
            "Episode:27 Score:46\n",
            "Episode:28 Score:-14\n",
            "Episode:29 Score:60\n",
            "Episode:30 Score:-44\n",
            "Episode:31 Score:46\n",
            "Episode:32 Score:20\n",
            "Episode:33 Score:38\n",
            "Episode:34 Score:36\n",
            "Episode:35 Score:56\n",
            "Episode:36 Score:60\n",
            "Episode:37 Score:-20\n",
            "Episode:38 Score:56\n",
            "Episode:39 Score:52\n",
            "Episode:40 Score:-48\n",
            "Episode:41 Score:44\n",
            "Episode:42 Score:-6\n",
            "Episode:43 Score:60\n",
            "Episode:44 Score:58\n",
            "Episode:45 Score:60\n",
            "Episode:46 Score:6\n",
            "Episode:47 Score:46\n",
            "Episode:48 Score:50\n",
            "Episode:49 Score:42\n",
            "Episode:50 Score:60\n",
            "Episode:51 Score:38\n",
            "Episode:52 Score:54\n",
            "Episode:53 Score:40\n",
            "Episode:54 Score:60\n",
            "Episode:55 Score:34\n",
            "Episode:56 Score:6\n",
            "Episode:57 Score:2\n",
            "Episode:58 Score:26\n",
            "Episode:59 Score:60\n",
            "Episode:60 Score:38\n",
            "Episode:61 Score:16\n",
            "Episode:62 Score:60\n",
            "Episode:63 Score:60\n",
            "Episode:64 Score:44\n",
            "Episode:65 Score:20\n",
            "Episode:66 Score:54\n",
            "Episode:67 Score:-20\n",
            "Episode:68 Score:60\n",
            "Episode:69 Score:58\n",
            "Episode:70 Score:40\n",
            "Episode:71 Score:60\n",
            "Episode:72 Score:-18\n",
            "Episode:73 Score:14\n",
            "Episode:74 Score:60\n",
            "Episode:75 Score:60\n",
            "Episode:76 Score:24\n",
            "Episode:77 Score:60\n",
            "Episode:78 Score:4\n",
            "Episode:79 Score:-16\n",
            "Episode:80 Score:60\n",
            "Episode:81 Score:16\n",
            "Episode:82 Score:54\n",
            "Episode:83 Score:-16\n",
            "Episode:84 Score:60\n",
            "Episode:85 Score:-12\n",
            "Episode:86 Score:60\n",
            "Episode:87 Score:60\n",
            "Episode:88 Score:60\n",
            "Episode:89 Score:52\n",
            "Episode:90 Score:60\n",
            "Episode:91 Score:20\n",
            "Episode:92 Score:28\n",
            "Episode:93 Score:60\n",
            "Episode:94 Score:56\n",
            "Episode:95 Score:46\n",
            "Episode:96 Score:30\n",
            "Episode:97 Score:60\n",
            "Episode:98 Score:60\n",
            "Episode:99 Score:42\n",
            "Episode:100 Score:60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Train Model*"
      ],
      "metadata": {
        "id": "jzcphHqv374f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_path = os.path.join('Training', 'Logs')"
      ],
      "metadata": {
        "id": "S2VNX-Yq38gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPXxbu-l3-Ue",
        "outputId": "9881612c-e1ae-470a-854a-9989f93766d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:318: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  def reset(self, **kwargs):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.learn(total_timesteps=20000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxNAi1b25MHk",
        "outputId": "80643ae4-d111-467c-b647-d6a20079c7d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging to Training/Logs/PPO_1\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 60       |\n",
            "|    ep_rew_mean     | -60      |\n",
            "| time/              |          |\n",
            "|    fps             | 426      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 4        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 60           |\n",
            "|    ep_rew_mean          | -60          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 549          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 7            |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056281523 |\n",
            "|    clip_fraction        | 0.0476       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.09        |\n",
            "|    explained_variance   | -0.00539     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 10.1         |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00331     |\n",
            "|    value_loss           | 51           |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 60          |\n",
            "|    ep_rew_mean          | -60         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 555         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 11          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009575617 |\n",
            "|    clip_fraction        | 0.00947     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.09       |\n",
            "|    explained_variance   | 0.0122      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 17.9        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -9.57e-05   |\n",
            "|    value_loss           | 68.9        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 60           |\n",
            "|    ep_rew_mean          | -60          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 501          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 16           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0003552013 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.08        |\n",
            "|    explained_variance   | 0.0362       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 27.7         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | 5.51e-05     |\n",
            "|    value_loss           | 71           |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 60           |\n",
            "|    ep_rew_mean          | -60          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 539          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 18           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041273455 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.09        |\n",
            "|    explained_variance   | 0.29         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 35.8         |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.000473    |\n",
            "|    value_loss           | 65.4         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 60          |\n",
            "|    ep_rew_mean          | -60         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 569         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 21          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012476295 |\n",
            "|    clip_fraction        | 0.129       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.07       |\n",
            "|    explained_variance   | 0.351       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 27.3        |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0101     |\n",
            "|    value_loss           | 69.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 60          |\n",
            "|    ep_rew_mean          | -60         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 576         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 24          |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014094293 |\n",
            "|    clip_fraction        | 0.214       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1          |\n",
            "|    explained_variance   | 0.658       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 12.4        |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0166     |\n",
            "|    value_loss           | 41.5        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 60           |\n",
            "|    ep_rew_mean          | -60          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 595          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 27           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0131680425 |\n",
            "|    clip_fraction        | 0.159        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.948       |\n",
            "|    explained_variance   | 0.759        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 14.3         |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.0111      |\n",
            "|    value_loss           | 28.1         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 60          |\n",
            "|    ep_rew_mean          | -60         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 613         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 30          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011061623 |\n",
            "|    clip_fraction        | 0.123       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.91       |\n",
            "|    explained_variance   | 0.663       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 17.6        |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.00788    |\n",
            "|    value_loss           | 30.2        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 60           |\n",
            "|    ep_rew_mean          | -60          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 627          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 32           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069522643 |\n",
            "|    clip_fraction        | 0.0651       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.865       |\n",
            "|    explained_variance   | 0.587        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 18.7         |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.00351     |\n",
            "|    value_loss           | 38.2         |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x7f9c511b07d0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Save Model*"
      ],
      "metadata": {
        "id": "9MQSqTnu5mju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('PPO')"
      ],
      "metadata": {
        "id": "ja1V_e905roF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_policy(model, env, n_eval_episodes=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADcgs8bW5skv",
        "outputId": "3b9e01e8-23e6-43b0-b9a9-4951b66ac9cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-49.6, 3.730951621235526)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}